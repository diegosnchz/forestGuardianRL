# ğŸ§  Sistema XAI (Explainable AI) - Forest Guardian RL

## DescripciÃ³n General

El sistema **XAI (Explainable AI)** de Forest Guardian RL proporciona interpretabilidad completa de las decisiones tomadas por los agentes autÃ³nomos (ALPHA y BRAVO). En lugar de ser una "caja negra", ahora puedes entender **por quÃ©** cada agente toma cada acciÃ³n, **quÃ© factores** influyen mÃ¡s, y **cÃ³mo** se distribuye la atenciÃ³n en el mapa.

### Componentes Principales

```
XAI System (Sistema de Inteligencia Explicable)
â”œâ”€â”€ ğŸ¯ Decisiones (AgentDecision)
â”‚   â””â”€â”€ Captura contexto completo de cada decisiÃ³n
â”œâ”€â”€ ğŸ—ºï¸ Mapas de AtenciÃ³n (Attention Maps)
â”‚   â””â”€â”€ VisualizaciÃ³n de quÃ© influye mÃ¡s en cada decisiÃ³n
â”œâ”€â”€ ğŸ“Š Importancia de Atributos (Importance Scores)
â”‚   â””â”€â”€ CuantificaciÃ³n de influencia de cada factor
â”œâ”€â”€ âš”ï¸ Razonamiento TÃ¡ctico (Tactical Reasoning)
â”‚   â””â”€â”€ JustificaciÃ³n role-especÃ­fica para cada decisiÃ³n
â””â”€â”€ ğŸ“ˆ Historiales y AnÃ¡lisis (History & Analytics)
    â””â”€â”€ Seguimiento y comparaciÃ³n multi-agente
```

---

## 1. Conceptos Fundamentales

### 1.1 AgentDecision (DecisiÃ³n del Agente)

Cada decisiÃ³n captura:

```python
@dataclass
class AgentDecision:
    timestamp: datetime          # CuÃ¡ndo se tomÃ³
    agent_id: str               # Identificador Ãºnico (ALPHA, BRAVO)
    agent_role: str             # Rol tÃ¡ctico (nearest, farthest)
    position: Tuple[int, int]   # PosiciÃ³n actual del agente
    action: int                 # CÃ³digo de acciÃ³n (0-6)
    action_name: str            # Nombre descriptivo ("Mover Arriba", etc.)
    grid_state: np.ndarray      # Estado del entorno
    explanation: str            # ExplicaciÃ³n textual
    tactical_reasoning: str     # Razonamiento tÃ¡ctico
    attention_map: np.ndarray   # Mapa de atenciÃ³n (matriz 0-1)
    importance_scores: Dict     # Importancia de cada factor
    alternative_actions: List   # Alternativas consideradas
    confidence: float           # Confianza en la decisiÃ³n (0-1)
    distance_to_target: float   # Distancia al objetivo
    water_level: int            # Agua disponible en tanque
```

### 1.2 Roles de Agentes

| Rol | Agente | Estrategia | Objetivo |
|-----|--------|-----------|----------|
| **nearest** | ALPHA ğŸ”µ | Respuesta RÃ¡pida | Minimizar tiempo de respuesta |
| **farthest** | BRAVO ğŸŸ  | ContenciÃ³n PerifÃ©rica | Prevenir propagaciÃ³n en perÃ­metro |

### 1.3 Acciones Disponibles

```
0: Mover Arriba â¬†ï¸
1: Mover Abajo â¬‡ï¸
2: Mover Izquierda â¬…ï¸
3: Mover Derecha â¡ï¸
4: Idle (Esperar) â¸ï¸
5: Apagar Fuego (radio 3x3) ğŸš’
6: Construir Cortafuegos ğŸ”¥
```

---

## 2. Sistema de Importancia de Atributos

### 2.1 Factores Analizados

El sistema XAI evalÃºa **8 factores clave** que influyen en las decisiones:

#### **1. Proximidad al Fuego** (proximidad_fuego)
- **Peso**: Variable (alto para ALPHA, bajo para BRAVO)
- **DescripciÃ³n**: Distancia en celdas al fuego mÃ¡s cercano
- **Rango**: 0-100 (normalizado por tamaÃ±o del grid)
- **FÃ³rmula**: `1.0 - (min_distance / max_distance)`

#### **2. Cantidad de Fuegos** (cantidad_fuegos)
- **Peso**: Moderado
- **DescripciÃ³n**: NÃºmero total de focos activos
- **Rango**: 0-100 (normalizado)
- **FÃ³rmula**: `num_fires / max_possible_fires`

#### **3. Cobertura PerifÃ©rica** (cobertura_perimetral)
- **Peso**: Alto para BRAVO, bajo para ALPHA
- **DescripciÃ³n**: MÃ¡xima distancia al perÃ­metro (solo BRAVO)
- **Rango**: 0-1
- **FÃ³rmula**: AnÃ¡lisis de posiciones en borde

#### **4. Ãrboles en Riesgo** (arboles_en_riesgo)
- **Peso**: Moderado-alto
- **DescripciÃ³n**: Ãrboles adyacentes a fuegos
- **Rango**: 0-100
- **FÃ³rmula**: Conteo ponderado por proximidad

#### **5. Densidad Local de Ãrboles** (densidad_arboles_local)
- **Peso**: Bajo-moderado
- **DescripciÃ³n**: Cantidad de Ã¡rboles en radio 3
- **Rango**: 0-1
- **FÃ³rmula**: `trees_in_radius / max_possible`

#### **6. Centralidad del Agente** (centralidad)
- **Peso**: Bajo
- **DescripciÃ³n**: QuÃ© tan alejado estÃ¡ del centro
- **Rango**: 0-1
- **FÃ³rmula**: Distancia euclidiana al centro normalizada

#### **7. Influencia del Viento** (influencia_viento)
- **Peso**: Moderado (si estÃ¡ disponible)
- **DescripciÃ³n**: Magnitud del vector de viento
- **Rango**: 0-1
- **FÃ³rmula**: `vector_magnitude / max_wind`

#### **8. Factor de ElevaciÃ³n** (factor_elevacion)
- **Peso**: Bajo (si estÃ¡ disponible)
- **DescripciÃ³n**: Promedio de elevaciÃ³n en radio
- **Rango**: 0-1
- **FÃ³rmula**: NormalizaciÃ³n de altura

### 2.2 VisualizaciÃ³n de Importancia

```
Importancia de Atributos - ALPHA
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Proximidad Fuego        â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 85.2%
Cantidad Fuegos         â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘ 62.5%
Arboles En Riesgo       â–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘ 48.3%
Densidad Arboles       â–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘ 32.1%
Centralidad            â–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ 15.7%
Influencia Viento      â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘  0.0%
Factor Elevacion       â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘  0.0%
```

---

## 3. Mapas de AtenciÃ³n (Attention Maps)

Los **mapas de atenciÃ³n** muestran visualmente dÃ³nde se concentra la "atenciÃ³n" del agente.

### 3.1 CÃ³mo se Generan

```python
# Matriz de atenciÃ³n (0-1)
attention_map = np.zeros((grid_size, grid_size))

# 1. PosiciÃ³n del agente: MÃXIMA atenciÃ³n (1.0)
attention_map[agent_r, agent_c] = 1.0

# 2. PosiciÃ³n del fuego objetivo: atenciÃ³n alta (0.9)
attention_map[fire_r, fire_c] = 0.9

# 3. Camino entre agente y fuego: atenciÃ³n gradual (0.1-0.5)
for cell in path:
    attention_map[cell] = 0.1 + (0.4 * proximity_to_target)

# 4. GAMMA (cortafuegos): atenciÃ³n en Ã¡rboles cerca de fuegos (0.6)
for tree in trees_near_fires:
    attention_map[tree_r, tree_c] = 0.6
```

### 3.2 InterpretaciÃ³n Visual

```
Mapa de AtenciÃ³n - ALPHA
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Rojo Oscuro (1.0)    â–“â–“â–“   MÃ¡xima atenciÃ³n - PosiciÃ³n del agente
Rojo Brillante (0.9) â–‘â–‘â–‘   Objetivo principal - Fuego a extinguir
Naranja (0.5)        â–‘â–‘â–‘   Ruta estratÃ©gica
Amarillo (0.2)       â–‘â–‘â–‘   Ãrea de influencia
Blanco (0.0)         â–‘â–‘â–‘   Zona no relevante
```

### 3.3 Caso de Uso: Entendiendo una DecisiÃ³n

```
DecisiÃ³n: ALPHA - Mover Abajo

ğŸ“Š Mapa de AtenciÃ³n:
   - MÃ¡xima atenciÃ³n en fuego a 2 celdas sur
   - Ruta clara hacia el objetivo
   - Ãrboles en riesgo detectados

ğŸ’¡ InterpretaciÃ³n:
   "El agente ve claramente el fuego abajo y se mueve directo"

âš”ï¸ Razonamiento TÃ¡ctico ALPHA:
   "Respuesta RÃ¡pida - Amenaza inmediata a 2 celdas"
```

---

## 4. Razonamiento TÃ¡ctico Role-EspecÃ­fico

### 4.1 ALPHA - Respuesta RÃ¡pida (Nearest)

**Doctrina Operacional:**
- âœ… Minimizar tiempo de respuesta
- âœ… Priorizar amenazas inmediatas
- âœ… SupresiÃ³n directa de fuegos

**Patrones de DecisiÃ³n:**
```
CONDICIÃ“N                    ACCIÃ“N ESPERADA
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
Fuego a <3 celdas           Movimiento directo hacia fuego
Fuego cercano + Ã¡rboles     Apagar si es accesible
En posiciÃ³n de apagar        Extinguir incendio (acciÃ³n 5)
Fuego lejano                 Buscar fuego mÃ¡s cercano
```

**Ejemplo de ExplicaciÃ³n ALPHA:**
```
ğŸ”µ TÃCTICA ALPHA - RESPUESTA RÃPIDA

Doctrina Operacional:
â€¢ Minimizar tiempo de respuesta
â€¢ Priorizar amenazas inmediatas
â€¢ SupresiÃ³n directa de fuegos

Estado: ğŸƒ AproximaciÃ³n rÃ¡pida
ETA: 2 movimientos

AnÃ¡lisis: Fuego detectado a 2 celdas al sur
AcciÃ³n: Mover Abajo para aproximarse rÃ¡pidamente
```

### 4.2 BRAVO - ContenciÃ³n PerifÃ©rica (Farthest)

**Doctrina Operacional:**
- âœ… Prevenir propagaciÃ³n en perÃ­metro
- âœ… Proteger Ã¡reas aÃºn no afectadas
- âœ… Crear defensa en profundidad

**Patrones de DecisiÃ³n:**
```
CONDICIÃ“N                    ACCIÃ“N ESPERADA
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
Fuego cercano pero ALPHA    Ignorar (dejar a ALPHA)
Fuego en perÃ­metro          Aproximarse a defender
MÃºltiples fuegos lejanos    Analizar patrÃ³n de propagaciÃ³n
Riesgo de expansiÃ³n         Cortafuegos preventivo
```

**Ejemplo de ExplicaciÃ³n BRAVO:**
```
ğŸŸ  TÃCTICA BRAVO - CONTENCIÃ“N PERIFÃ‰RICA

Doctrina Operacional:
â€¢ Prevenir propagaciÃ³n en perÃ­metro
â€¢ Proteger Ã¡reas aÃºn no afectadas
â€¢ Crear defensa en profundidad

Estado: ğŸ›¡ï¸ Vigilancia del perÃ­metro
PosiciÃ³n EstratÃ©gica: Esquina NE (mÃ¡xima cobertura)

AnÃ¡lisis: ALPHA maneja fuego cercano
AcciÃ³n: Patrullar perÃ­metro y preparar defensa
```

---

## 5. CÃ³mo Usar el Sistema XAI

### 5.1 En Streamlit (AplicaciÃ³n Web)

#### **PestaÃ±a 6: Explicabilidad IA (XAI)**

```
ğŸ§  Explicabilidad IA (XAI) - AnÃ¡lisis de Decisiones
â””â”€â”€ Selectores
    â”œâ”€â”€ Agente (ALPHA / BRAVO)
    â””â”€â”€ Paso de SimulaciÃ³n
    
â””â”€â”€ Sub-pestaÃ±as
    â”œâ”€â”€ ğŸ“Š Ãšltima DecisiÃ³n
    â”‚   â”œâ”€â”€ Razonamiento TÃ¡ctico Completo
    â”‚   â”œâ”€â”€ Importancia de Atributos (grÃ¡fico)
    â”‚   â””â”€â”€ Alternativas Consideradas
    â”‚
    â”œâ”€â”€ ğŸ“ˆ EvoluciÃ³n Temporal
    â”‚   â”œâ”€â”€ Timeline de Distancia/Confianza/Agua
    â”‚   â”œâ”€â”€ DistribuciÃ³n de Acciones
    â”‚   â”œâ”€â”€ Scatter: Confianza vs Distancia
    â”‚   â””â”€â”€ Heatmap de Importancia Evolutiva
    â”‚
    â”œâ”€â”€ ğŸ—ºï¸ Mapas de AtenciÃ³n por Paso
    â”‚   â”œâ”€â”€ Slider para seleccionar paso
    â”‚   â”œâ”€â”€ VisualizaciÃ³n de AtenciÃ³n
    â”‚   â”œâ”€â”€ ExplicaciÃ³n de la DecisiÃ³n
    â”‚   â””â”€â”€ Razonamiento TÃ¡ctico Detallado
    â”‚
    â””â”€â”€ ğŸ“‰ AnÃ¡lisis EstadÃ­stico Multi-Agente
        â”œâ”€â”€ ComparaciÃ³n de Agentes
        â”œâ”€â”€ MÃ©tricas Globales
        â”œâ”€â”€ Historial Tabular
        â””â”€â”€ ExportaciÃ³n a JSON
```

### 5.2 En CÃ³digo Python

#### **Inicializar el Explainer**

```python
from xai_explainer import XAIExplainer

# Crear explainer para grid 10x10
explainer = XAIExplainer(grid_size=10, enable_mongodb=False)
```

#### **Generar ExplicaciÃ³n de DecisiÃ³n**

```python
# DespuÃ©s de que ALPHA toma una decisiÃ³n
decision = explainer.explain_decision(
    agent_id="ALPHA",
    agent_role="nearest",
    position=(5, 5),           # PosiciÃ³n actual
    action=1,                  # CÃ³digo de acciÃ³n
    grid_state=obs,            # Estado del entorno
    obs={'step': step},        # Observaciones extras
    water_level=env.water_tanks[0]  # Agua disponible
)

# Acceder a los datos
print(decision.explanation)          # Texto explicativo
print(decision.tactical_reasoning)   # Razonamiento tÃ¡ctico
print(decision.importance_scores)    # Factores de importancia
print(decision.confidence)           # Confianza (0-1)
```

#### **Visualizar Mapas de AtenciÃ³n**

```python
from xai_visualization import create_attention_heatmap
import matplotlib.pyplot as plt

# Crear y mostrar mapa
fig = create_attention_heatmap(
    attention_map=decision.attention_map,
    grid_state=decision.grid_state,
    agent_position=decision.position,
    title="AnÃ¡lisis de AtenciÃ³n ALPHA"
)

plt.show()
```

#### **Generar GrÃ¡ficos de Importancia**

```python
from xai_visualization import create_importance_chart

fig = create_importance_chart(
    importance_scores=decision.importance_scores,
    title="Factores de DecisiÃ³n"
)

fig.show()
```

#### **Analizar MÃºltiples Decisiones**

```python
from xai_visualization import (
    create_decision_timeline,
    create_action_distribution_chart,
    create_multi_agent_comparison
)

# Timeline de distancia al objetivo
fig_timeline = create_decision_timeline(
    decisions=agent_decisions,
    metric='distance_to_target'
)

# DistribuciÃ³n de acciones
fig_actions = create_action_distribution_chart(agent_decisions)

# ComparaciÃ³n multi-agente
fig_comparison = create_multi_agent_comparison({
    'ALPHA': alpha_decisions,
    'BRAVO': bravo_decisions
})
```

#### **Exportar Reportes**

```python
from xai_visualization import export_decision_report

# Exportar una decisiÃ³n
export_decision_report(decision, "reporte_alpha_paso_42.html")

# Exportar historial completo
explainer.export_history("historial_completo.json")
```

### 5.3 En train_and_test.py (IntegraciÃ³n Completa)

```python
from xai_explainer import XAIExplainer

def make_the_magic(conf):
    """
    FunciÃ³n principal con integraciÃ³n XAI
    """
    # ... cÃ³digo existente ...
    
    # Inicializar explainer
    xai_explainer = XAIExplainer(grid_size=conf['grid_size'], enable_mongodb=False)
    
    # En el loop principal de simulaciÃ³n
    while not done:
        # Decisiones de agentes
        action_blue = agent_blue.decide(obs, positions[0])
        action_orange = agent_orange.decide(obs, positions[1])
        
        # GENERAR EXPLICACIONES XAI (nuevo)
        decision_blue = xai_explainer.explain_decision(
            agent_id="ALPHA",
            agent_role="nearest",
            position=positions[0],
            action=action_blue,
            grid_state=obs.copy(),
            obs={'step': step},
            water_level=water_tanks[0]
        )
        
        decision_orange = xai_explainer.explain_decision(
            agent_id="BRAVO",
            agent_role="farthest",
            position=positions[1],
            action=action_orange,
            grid_state=obs.copy(),
            obs={'step': step},
            water_level=water_tanks[1]
        )
        
        # Guardar decisiones para anÃ¡lisis posterior
        all_decisions.append(decision_blue)
        all_decisions.append(decision_orange)
        
        # Ejecutar simulaciÃ³n
        obs, reward, terminated, truncated, info = env.step(...)
        
        step += 1
    
    # Exportar anÃ¡lisis final
    xai_explainer.export_history("analisis_mision_xai.json")
    
    return results
```

---

## 6. Casos de Uso PrÃ¡cticos

### 6.1 Debuggear Comportamiento AnÃ³malo

**Problema**: "Â¿Por quÃ© BRAVO ignora un fuego cercano?"

**SoluciÃ³n XAI**:
1. Ir a pestaÃ±a "Explicabilidad IA"
2. Seleccionar agente "BRAVO"
3. Encontrar el paso problemÃ¡tico
4. Revisar mapa de atenciÃ³n â†’ "Ahh, ALPHA ya estÃ¡ manejando ese fuego"
5. Revisar razonamiento tÃ¡ctico â†’ "BRAVO prioriza perÃ­metro sobre fuegos cercanos"

### 6.2 Validar Mejoras de Entrenamiento

**Pregunta**: "Â¿MejorÃ³ el comportamiento despuÃ©s del Ãºltimo entrenamiento?"

**Proceso XAI**:
1. Ejecutar simulaciÃ³n antigua â†’ Generar explicaciones XAI
2. Ejecutar simulaciÃ³n nueva â†’ Generar explicaciones XAI
3. Comparar en pestaÃ±a "AnÃ¡lisis EstadÃ­stico"
4. Analizar:
   - Â¿CambiÃ³ la distribuciÃ³n de acciones?
   - Â¿MejorÃ³ la confianza promedio?
   - Â¿ReducciÃ³n de distancia al objetivo?

### 6.3 Investigar Correlaciones

**Pregunta**: "Â¿Cuando la confianza es baja, quÃ© factores importan mÃ¡s?"

**Proceso XAI**:
1. Ir a "AnÃ¡lisis EstadÃ­stico Multi-Agente"
2. Observar scatter: Confianza vs Distancia
3. Identificar puntos de baja confianza
4. Revisar importancia de factores en esos pasos
5. Encontrar correlaciones interesantes

---

## 7. Formato de ExportaciÃ³n JSON

### 7.1 Estructura del Historial Exportado

```json
{
  "statistics": {
    "total_decisions": 100,
    "action_counts": {
      "Mover Arriba": 15,
      "Mover Abajo": 20,
      "Apagar Fuego": 45,
      ...
    },
    "agent_stats": {
      "ALPHA": {
        "total_decisions": 50,
        "average_confidence": 0.72,
        "average_distance_to_target": 2.5
      },
      "BRAVO": {
        "total_decisions": 50,
        "average_confidence": 0.68,
        "average_distance_to_target": 4.2
      }
    }
  },
  "histories": {
    "ALPHA": [
      {
        "timestamp": "2024-01-15T10:30:45.123456",
        "agent_id": "ALPHA",
        "agent_role": "nearest",
        "position": [5, 5],
        "action": 1,
        "action_name": "Mover Abajo",
        "explanation": "...",
        "tactical_reasoning": "...",
        "importance_scores": {
          "proximidad_fuego": 0.85,
          "cantidad_fuegos": 0.62,
          ...
        },
        "distance_to_target": 2.0,
        "confidence": 0.72
      },
      ...
    ],
    "BRAVO": [...]
  }
}
```

---

## 8. IntegraciÃ³n con MongoDB Atlas (Opcional)

Si tienes MongoDB Atlas configurado, el sistema XAI puede almacenar explicaciones:

```python
# En app.py - sidebar
with st.sidebar.expander("âš™ï¸ ConfiguraciÃ³n XAI"):
    mongodb_uri = st.text_input("MongoDB Atlas URI (opcional)")
    st.session_state.mongodb_uri = mongodb_uri
```

```python
# En run_mission
if mongodb_uri:
    explainer = XAIExplainer(
        grid_size=grid_size,
        enable_mongodb=True  # Almacenar en MongoDB
    )
```

---

## 9. Troubleshooting

### Problema: "No hay decisiones XAI disponibles"

**Causa**: La simulaciÃ³n no capturÃ³ decisiones
**SoluciÃ³n**:
1. Inicia una misiÃ³n completa
2. Espera a que termine
3. Regresa a la pestaÃ±a XAI
4. Las decisiones deberÃ­an aparecer

### Problema: "Mapa de atenciÃ³n se ve oscuro"

**Causa**: Todos los valores son muy bajos
**SoluciÃ³n**:
1. Verificar que hay fuegos activos
2. Asegurarse que el grid tiene Ã¡rboles
3. Revisar que el agente estÃ¡ activo

### Problema: "Error al exportar historial"

**Causa**: No hay suficientemente decisiones capturadas
**SoluciÃ³n**:
1. Ejecutar simulaciÃ³n mÃ¡s larga
2. Asegurarse que hay decisiones del agente seleccionado
3. Revisar consola para mensajes de error

---

## 10. Recursos Adicionales

### Documentos Relacionados
- [MONGODB_ATLAS_SETUP.md](MONGODB_ATLAS_SETUP.md) - IntegraciÃ³n con MongoDB
- [FOLIUM_ATLAS_README.md](FOLIUM_ATLAS_README.md) - Mapas geoespaciales
- [MONGODB_INTEGRATION_SUMMARY.md](MONGODB_INTEGRATION_SUMMARY.md) - Resumen de integraciÃ³n

### Archivos del Sistema
- `xai_explainer.py` - MÃ³dulo principal (721 lÃ­neas)
- `xai_visualization.py` - Visualizaciones (850+ lÃ­neas)
- `test_xai_system.py` - Suite de tests (350+ lÃ­neas)

### Scripts de Ejemplo
```bash
# Ejecutar tests
python test_xai_system.py

# Ejecutar aplicaciÃ³n con XAI
streamlit run app.py
```

---

## 11. Roadmap Futuro

### PrÃ³ximas CaracterÃ­sticas Planeadas

- [ ] **SHAP Values**: Explicaciones aditivas de Shapley
- [ ] **LIME**: Explicaciones locales interpretables
- [ ] **Attention Visualization**: Mapas de atenciÃ³n mejorados
- [ ] **Decision Trees**: ExtracciÃ³n de reglas de decisiÃ³n
- [ ] **Counterfactual Explanations**: "Â¿QuÃ© hubiera pasado si...?"
- [ ] **Real-time XAI**: Explicaciones durante la simulaciÃ³n en vivo

---

## ConclusiÃ³n

El sistema XAI de Forest Guardian RL transforma agentes opacos en sistemas interpretables y auditables. Ahora puedes:

âœ… Entender cada decisiÃ³n
âœ… Validar comportamientos
âœ… Debuggear problemas
âœ… Mejorar entrenamientos
âœ… Demostrar confiabilidad

**Â¡Bienvenido a la IA Explicable!** ğŸ§ âœ¨

---

*DocumentaciÃ³n actualizada: Enero 2024*
*Sistema XAI v1.0 - Forest Guardian RL*
